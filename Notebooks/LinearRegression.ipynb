{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a dataset and we decide to plot it as so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cricketpoints.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case, the x variable is the amount of cricket chirps per minute, and the y variable is the temperature in celsius. \n",
    "\n",
    "We can draw a line \"through\" the data points, as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/CricketLine.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that the relationship between chirps per minute and the temperature in celisus is linear. Using mathematics, we know that the equation for a line is\n",
    "> y = mx + b\n",
    "- y is the temperature in celsius\n",
    "- x represents the cricket chirps per minute\n",
    "- b represents the y intercept\n",
    "- m is the slope of the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ML, the equation is a bit different:\n",
    "> y' = b + w1x1\n",
    "- y' is the label that we are predicting\n",
    "- b is the bias (y intercept)\n",
    "- w1 is the weight of feature one. Weight is the same concept of slope \"m\"\n",
    "- x1 is the feature (known input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case, our model has only one feature, but in the real world, models can have up to millions of features, denoted\n",
    "> y' = b + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training a model simply means learning (determining) good values for all the weights and the bias from labeled examples**. In supervised learning, an ML algorithm builds a model by examining many examples and attempting to find a model that minimizes **loss**. This process is called empirical risk minimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is the penalty for a bad prediction. In other words, loss tells us how bad the model's prediction was for a single example. A perfect prediction means a loss of zero, otherwise the loss is greater. \n",
    "\n",
    "**The overall goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples.**\n",
    "\n",
    "For example, see the charts below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loss](img/LossSidebySide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the charts above, the one on the left has high loss, while the one on the right has low loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way to create a mathematical function that allows us to aggregate the individual losses in a meaningful manner. In other words, there is a way for us to visualize loss such that we know how to counter it, and that is where our **loss function** comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squared Loss: A Popular Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression models examined in these notes use a loss function called **squared loss** (L2 loss). The squared loss for any single example is as follows:\n",
    "\n",
    "= The square of the difference between the label and the prediction  \n",
    "= (observation - prediction(x))<sup>2</sup>  \n",
    "= **(y - y')<sup>2</sup>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is the average squared loss per example in a dataset. To calculate MSE, sum up all of the squared losses for individual examples and then divide by the number of examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mse](img/mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this formula, the sigma means 'sum'. Therefore, it could be said that MSE is equal to 1/n times the sum of (y-prediction(x))<sup>2</sup> for every pair (x, y) in the set D.**\n",
    "\n",
    "- (x, y) is an example in which \n",
    "    - x is the set of features that the model uses to make predictions\n",
    "    - y is the example's label\n",
    "- prediction(x) is a function of the weights and bias in combination with the set features of x\n",
    "- D is a data set of many labeled examples, which are (x, y) pairs\n",
    "- N is the number of examples in D\n",
    "\n",
    "Although MSE is commonly used in ML, it is not the only nor the best loss function available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important parts of training a ML algorithm is reducing loss. There are many different ways to reduce loss, but for this example, we will look at one approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Approach\n",
    "This can best be compared to a giant game of \"hot and cold\". In essence, the model starts with a random weight and bias, and then plugs that prediction into a loss function. With the loss it computes, it changes the values of the weights and bias in order to attempt to reduce loss. It does this over and over again (hence iterative) until the loss is 0 or stops declining or increasing at all. See this diagram: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](img/IterativeDiagram.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"compute loss\" part of the diagram does just that. It uses a loss function to calculate the loss for a given example of b and w<sub>1</sub>. After computing the loss, it feeds it to another function that computes new values for b and w<sub>1</sub>.  \n",
    "\n",
    "Once the loss reaches zero, stops changing, or changes extremely slowly, the model knows that it has **converged**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterative approach above contains a green box labeled \"compute parameter updates\", but what exactly does that mean? That is where **Gradient Descent** comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we had the time and resources to calculate the loss for all possible values of w<sub>1</sub>. For the kind of problems we've been examining, the resulting plot of loss vs w<sub>1</sub> will always be convex, like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![convex](img/convex.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex loss vs. weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tend to model the relationship between loss and weight in this form because it is easy to identify when the slope is exactly zero. In other words, complex problems have only one minimum. This minimum is where the loss function converges.\n",
    "\n",
    "Of course, calculating the loss function for every possible value of w<sub>1</sub> would be nearly impossible, and extremely inefficient. A more popular mechanism in modern day ML is called **gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage of gradient descent is to pick an arbitrary starting value for w<sub>1</sub>. This value does not matter all to much. In fact, any algorithms tend to set this initial value to 0, or choose a  random value. In the example below, a starting point slightly greater than 0 was chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradientdescentstart](img/gdstart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm then calculates the gradient of the loss curve at the starting point. In the example above, the gradient of the loss is equal to the derivative (slope) of the curve, and tells you which way is \"warmer\", and which way is \"colder\". When there are multiple weights, the gradient is a vector of partial derivatives with respect to the weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a gradient is a vector, it has two core characteristics:\n",
    "- a direction\n",
    "- a magnitude\n",
    "\n",
    "The gradient always points in the direction of the steepest increase in the loss function. The algorithm takes a step in the direction of the negative gradient in order to reduce loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![negativegradient](img/negativegradient.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the next point along the loss function curve, the algorithm adds some fraction of the gradient's magnitude to the starting point, as shown: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradientstep](img/gradientstep.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm then repeats this process, getting closer and closer to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously noted, the gradient vector has both a direction and a magnitude. Gradient descent algorithms multiply the gradient by a scalar known as the learning rate in order to determine the next point. For example, if the gradient magnitude is 2.5 and the learning rate is 0.01, then the algorithm will pick the next point 0.025 away from the previous point.\n",
    "\n",
    "**Hyperparameters** are the knobs that programmers tweak in ML algorithms. Most ML programmers spend a fair amount of time tuning the learning rate. \n",
    "\n",
    "Picking a learning rate that is too small will result in learning taking too long:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![toosmall](img/toosmall.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if the learning rate is too large, the next point will essentially bounce back and forth across the bottom of the well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TooLarge](img/LearningRateTooLarge.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every regression problem, there exists a \"goldilocks\" learning rate. If you know that the gradient of the loss function is small then you can try a large learning rate, which compensates for the small gradient and results in larger step size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JustRight](img/LearningRateJustRight.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "In gradient descent, a **batch** is the total number of examples you use to calculate a gradient in a single iteration. To this point, we have assumed that the batch has been the entire data set. In real life, data sets often contain billions or even hundreds of billions of examples. To add on, real life data sets also tend to contain huge numbers of features. A very large batch may cause even a single iteration to take a very long time to compute.\n",
    "\n",
    "To tackle this problem, ML engineers tend to attempt to get the right gradient on average for much less computation. By choosing examples at random from the data set, we could estimate a big average. **Stochastic Gradient Descent** takes this idea to the extreme--it only uses a single exaple (a batch size of 1) per iteration. Given enough iterations, it works, but is very noisy. \n",
    "\n",
    "**Mini-batch stochastic gradient descent)** is a compramise between full batch iteration and SGD. A mini batch is typically between 10 to 1,000 examples chosen at random. \n",
    "\n",
    "**For this example, we focused on gradient descent for a single feature, but it also works on feature sets that contain multiple features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
